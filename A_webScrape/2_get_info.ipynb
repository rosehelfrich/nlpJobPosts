{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Hide the authKey in .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load the variables from .env\n",
    "authKey = os.getenv('authKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame()\n",
    "url_df['Job Links'] = pd.read_json('url_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to focus on only the data science job posts\n",
    "# Drop duplicate urls.\n",
    "url_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "# Drop urls with software in the url. \n",
    "drop_software = url_df[url_df['Job Links'].str.contains(\"software\", na=False)].index\n",
    "url_df.drop(index=drop_software, axis=0, inplace=True)\n",
    "\n",
    "# Drop urls with engineer in the url. \n",
    "engineer_df = url_df[url_df['Job Links'].str.contains(\"engineer\", na=False)]\n",
    "url_df.drop(index=engineer_df.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.to_csv('url_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it doesn't already exist, then un-comment-out the below \n",
    "#raw_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data for each of the urls\n",
    "# Fetch data then extract data\n",
    "# This uses a Rest API \n",
    "for url in url_df['Job Links']:\n",
    "\n",
    "    posting_r = requests.post(\n",
    "        \"https://api.zyte.com/v1/extract\",\n",
    "        auth=(authKey, \"\"),\n",
    "        json={\n",
    "            \"url\": url,\n",
    "            \"httpResponseBody\": True,\n",
    "            \"jobPosting\": True,\n",
    "            \"jobPostingOptions\": {\"extractFrom\":\"httpResponseBody\"},\n",
    "        },\n",
    "    )\n",
    "    http_posting_body: bytes = b64decode(\n",
    "        posting_r.json()[\"httpResponseBody\"])\n",
    "    jobPosting = posting_r.json()[\"jobPosting\"]\n",
    "\n",
    "    # Format to df and add row\n",
    "    add_job = pd.json_normalize(jobPosting)\n",
    "    raw_df = raw_df.merge(add_job, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv('raw_info_df.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
